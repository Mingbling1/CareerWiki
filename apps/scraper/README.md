# Empliq - Web Scraper

Scripts para buscar sitios web oficiales de empresas peruanas.

## ğŸ“ Estructura

```
apps/scraper/
â”œâ”€â”€ package.json          # Dependencias Node.js (Puppeteer)
â”œâ”€â”€ google-search.js      # BÃºsqueda individual con Puppeteer
â”œâ”€â”€ batch-search.js       # Procesamiento por lotes
â”œâ”€â”€ enrich_tiers.py       # Mapeo RUC -> Nombre (Python)
â””â”€â”€ README.md
```

## ğŸš€ InstalaciÃ³n

```bash
cd apps/scraper

# Instalar dependencias (incluye Puppeteer y Chrome)
npm install

# Si hay problemas con Puppeteer, instalar Chrome manualmente:
npx puppeteer browsers install chrome
```

## ğŸ“– Uso

### BÃºsqueda individual
```bash
# Buscar website de una empresa
node google-search.js "Banco de CrÃ©dito del PerÃº"

# Test con varias empresas
node google-search.js --test
```

### Procesamiento por lotes
```bash
# Procesar 10 empresas del Tier 1
node batch-search.js --tier 1 --limit 10

# Continuar desde donde se quedÃ³
node batch-search.js --tier 1 --limit 50 --continue

# Procesar Tier 2
node batch-search.js --tier 2 --limit 20
```

### Enriquecer datos (mapear RUC -> Nombre)
```bash
# Requiere el archivo del padrÃ³n SUNAT
python enrich_tiers.py
```

## ğŸ“Š Datos Disponibles

Los archivos en `/data/` ya estÃ¡n enriquecidos con nombres de empresa:

| Tier | Criterio | Empresas | Archivo |
|------|----------|----------|---------|
| 1 | â‰¥1000 trabajadores | 915 | tier1_mega_enriched.csv |
| 2 | 500-999 trabajadores | 798 | tier2_grandes_enriched.csv |
| 3 | 100-499 trabajadores | 4,410 | tier3_medianas_enriched.csv |

## ğŸ”§ ConfiguraciÃ³n Anti-Ban

El scraper implementa mÃºltiples tÃ©cnicas para evitar bloqueos:

- **Delays largos**: 10-20 segundos entre bÃºsquedas
- **Pausas largas**: 1-2 minutos cada 10 bÃºsquedas
- **User agents rotativos**: Simula diferentes navegadores
- **Escritura humana**: Delays aleatorios al escribir
- **Scroll humano**: Simula comportamiento de lectura

## ğŸ“‚ Archivos de Salida

```
data/scraped/
â”œâ”€â”€ tier1_progress.json   # Progreso guardado
â”œâ”€â”€ tier1_results.csv     # Resultados con websites
â”œâ”€â”€ tier2_progress.json
â”œâ”€â”€ tier2_results.csv
â””â”€â”€ ...
```

## âš ï¸ Consideraciones

- Google puede banear temporalmente si se hacen muchas bÃºsquedas
- Recomendado: mÃ¡ximo 50-100 bÃºsquedas por sesiÃ³n
- Si aparece CAPTCHA, esperar unas horas antes de continuar
- El progreso se guarda automÃ¡ticamente, se puede retomar con `--continue`

## ğŸ› Troubleshooting

### "Could not find Chrome"
```bash
npx puppeteer browsers install chrome
```

### El script se queda colgado
- Verificar conexiÃ³n a internet
- Probar con `headless: false` para ver el navegador
- Aumentar timeouts en el cÃ³digo
